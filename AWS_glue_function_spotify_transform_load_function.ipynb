{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('aws_glue').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.200.10.123:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>aws_glue</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1c189e09760>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "sc=SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job=Job(glueContext)\n",
    "#don't have to remember this, this is default in the aws glue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://spotify-daily-data-project/raw_data/to_processed\"\n",
    "source_dyf = glueContext.create_dynamic_frame_from_options(\n",
    "    conntection_type=\"S3\",\n",
    "    connection_options={\"paths\":[s3_path]},\n",
    "    format=\"json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df= source_dyf.toDF() #converting the JSON to Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = spotify_df.withColumn(\"items\", explode(\"items\")).show(5)\n",
    "#explode will break the row containing multiple rows in same line into diff rows respec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spotify_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"items\", explode(\"items\")).select(\n",
    "    col(\"items.track.album.id\").alias(\"album_id\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"items\", explode(\"items\")).select(\n",
    "    col(\"items.track.album.name\").alias(\"album_name\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_album(df):\n",
    "    df=df.withColumn(\"items\",explode=(\"items\")).select(\n",
    "        col(\"items.track.album.id\").alias(\"album_id\"),\n",
    "        col(\"items.track.album.name\").alias(\"album_name\"),\n",
    "        col(\"items.track.album.release_date\").alias(\"album_name\"),\n",
    "        col(\"items.track.album.total_tracks\").alias(\"total_tracks\"),\n",
    "        col(\"items.tracks.album.external_urls_spotify\").alias(\"url\")).drop_duplicates(['album_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_artists(df):\n",
    "    df_items_exploded = df.select(explode(col(\"items\")).alias(\"item\"))\n",
    "\n",
    "    df_artist_exploded=df_items_exploded.select(explode(col(\"items\")).alias(\"item\")).select(explode(col(\"item.track.artists\")).alias(\"artist\")).show(5)\n",
    "\n",
    "    df_artist=df_artist_exploded.select(\n",
    "        col(\"artist.id\").alias(\"artist_id\"),\n",
    "        col(\"artist.name\").alias(\"artist_name\"),\n",
    "        col(\"artist.external_urls.spotify\").alias(\"external_urls\")).drop_duplicates([\"artist_id\"])\n",
    "    return df_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_songs(df):\n",
    "    df_exploded = df.select(explode(col(\"items\")).alias(\"item\"))\n",
    "    df_songs= df_exploded.select(\n",
    "        col(\"item.track.id\").alias(\"songs_id\"),\n",
    "        col(\"item.track.name\").alias(\"songs_name\"),\n",
    "        col(\"item.track.duration_ms\").alias(\"duration_ms\"),\n",
    "        col(\"item.track.external_urls.spotify\").alias(\"external_urls\"),\n",
    "        col(\"item.track.popularity\").alias(\"popularity\"),\n",
    "        col(\"item.added_at\").alias(\"songs_added\"),\n",
    "        col(\"item.track.album.id\").alias(\"album_id\"),\n",
    "        col(\"item.track.artists\")[0][\"id\"].alias(\"artist_id\")\n",
    "\n",
    "    ).drop_duplicates(['songs_id'])\n",
    "\n",
    "    df_songs=df_songs.withColumn(\"songs_added\", to_date(col(\"songs_added\")))\n",
    "    return df_songs\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_df=process_album(spotify_df)\n",
    "album_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df= process_artists(spotify_df)\n",
    "artist_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df=process_songs(spotify_df)\n",
    "song_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_s3(df, path_suffix, format_type='csv'):\n",
    "    #changing the spark df to dynamic frame so that it can directly write to the s3 bucket\n",
    "    dynamic_frame= DynamicFrame.fromDF(df, glueContext,\"dynamic_frame\")\n",
    "\n",
    "    glueContext.write_dynamic_frame.from_Options(\n",
    "        frame= dynamic_frame,\n",
    "        connection_type = \"s3\",\n",
    "        connection_options={\"path\",\"s3://spotify-daily-project/transformed_data/{path_suffix}/\"},\n",
    "        format = format_type\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3(album_df,\"album/album_transformed{}\".format(datetime.now().strftime(\"%Y-%m-%d\")), 'csv')\n",
    "#datetime.now will create the file named with datetime as suffix\n",
    "write_to_s3(artist_df,\"artist/artist_transformed{}\".format(datetime.now().strftime(\"%Y-%m-%d\")), 'csv')\n",
    "write_to_s3(song_df,\"songs/songs_transformed{}\".format(datetime.now().strftime(\"%Y-%m-%d\")), 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, this will list out the s3 bucket and aim is to move processes file to \n",
    "# processed folder and delete the files into the to_processed folder.\n",
    "\n",
    "#this particular func will list out the to_processed files first!\n",
    "def list_s3_objects(bucket, prefix):\n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix = prefix)\n",
    "    keys = [content['Key'] for content in response.get('Contents', []) if content['Key'].endswith('.json')]\n",
    "    return keys\n",
    "\n",
    "bucket_name = \"spotify-daily-data-project\"\n",
    "prefix = 'raw_data/to_processed/'\n",
    "spotify_keys= list_s3_objects(bucket_name, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will do the move and delete opertion on to the to_processed folder\n",
    "import boto3\n",
    "\n",
    "def move_and_delete_files(spotify_keys, Bucket):\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    for key in spotify_keys:\n",
    "        copy_source = {\n",
    "            'Bucket' : Bucket,\n",
    "            'Key': key\n",
    "        }\n",
    "\n",
    "        #Define the destination key\n",
    "        destination_key = 'raw_data/processed/' + key.split(\"/\")[-1]\n",
    "\n",
    "        #copy the file to the new location\n",
    "        s3_resource.meta.client.copy(copy_source, Bucket, destination_key)\n",
    "\n",
    "        #delete the original file\n",
    "        s3_resource.Object(Bucket, key).delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_delete_files(spotify_keys, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
